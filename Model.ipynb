{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Remove duplicates\n",
    "train_data.drop_duplicates(subset=['PRODUCT_ID'], inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "train_data.fillna('', inplace=True)\n",
    "test_data.fillna('', inplace=True)\n",
    "\n",
    "# Remove outliers\n",
    "train_data = train_data[train_data['PRODUCT_LENGTH'] > 0]\n",
    "\n",
    "# Preprocess text data\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub('[^A-Za-z]', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "train_data['TITLE'] = train_data['TITLE'].apply(preprocess_text)\n",
    "train_data['DESCRIPTION'] = train_data['DESCRIPTION'].apply(preprocess_text)\n",
    "train_data['BULLET_POINTS'] = train_data['BULLET_POINTS'].apply(preprocess_text)\n",
    "\n",
    "test_data['TITLE'] = test_data['TITLE'].apply(preprocess_text)\n",
    "test_data['DESCRIPTION'] = test_data['DESCRIPTION'].apply(preprocess_text)\n",
    "test_data['BULLET_POINTS'] = test_data['BULLET_POINTS'].apply(preprocess_text)\n",
    "\n",
    "# Feature engineering\n",
    "from scipy import sparse\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=500, dtype=np.float32)\n",
    "title_features = vectorizer.fit_transform(train_data['TITLE'])\n",
    "description_features = vectorizer.fit_transform(train_data['DESCRIPTION'])\n",
    "bullet_points_features = vectorizer.fit_transform(train_data['BULLET_POINTS'])\n",
    "product_type_features = np.array(train_data['PRODUCT_TYPE_ID']).reshape(-1, 1)\n",
    "features = sparse.hstack((title_features, description_features, bullet_points_features, product_type_features))\n",
    "\n",
    "# Scale the features\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=features.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_absolute_error', optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', restore_best_weights=True)\n",
    "#Train the model\n",
    "history = model.fit(features, train_data['PRODUCT_LENGTH'].values, epochs=40, batch_size=64, callbacks=[early_stopping])\n",
    "\n",
    "#Evaluate the model on the training data\n",
    "train_predictions = model.predict(features)\n",
    "train_mae = mean_absolute_error(train_data['PRODUCT_LENGTH'].values, train_predictions)\n",
    "print('Training MAE:', train_mae)\n",
    "\n",
    "# Make predictions on the test set\n",
    "title_features = vectorizer.transform(test_data['TITLE']).toarray()\n",
    "description_features = vectorizer.transform(test_data['DESCRIPTION']).toarray()\n",
    "bullet_points_features = vectorizer.transform(test_data['BULLET_POINTS']).toarray()\n",
    "product_type_features = np.array(test_data['PRODUCT_TYPE_ID']).reshape(-1, 1)\n",
    "features = np.concatenate((title_features, description_features, bullet_points_features, product_type_features), axis=1)\n",
    "features = scaler.transform(features)\n",
    "predictions = model.predict(features)\n",
    "\n",
    "# Prepare submission file\n",
    "submission = test_data[['PRODUCT_ID']].copy()\n",
    "submission['PRODUCT_LENGTH'] = predictions\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "# import pandas as pd\n",
    "\n",
    "# Load actual and predicted values\n",
    "actual = pd.read_csv('/kaggle/input/amazon-product-length-prediction-dataset/dataset/sample_submission.csv')\n",
    "predicted = pd.read_csv('/kaggle/working/submission.csv')\n",
    "\n",
    "# Compute the mean absolute percentage error\n",
    "mape = mean_absolute_percentage_error(actual['PRODUCT_LENGTH'], predicted['PRODUCT_LENGTH'])\n",
    "\n",
    "# Print the score\n",
    "score = max(0, 100 * (1 - mape))\n",
    "print('Score:', score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
